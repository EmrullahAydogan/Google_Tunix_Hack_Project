# Google Tunix Hack - AraÅŸtÄ±rma NotlarÄ±

## ğŸ“‹ YarÄ±ÅŸma Ã–zeti

**YarÄ±ÅŸma AdÄ±:** Google Tunix Hack - Train a model to show its work
**Platform:** Kaggle
**Ã–dÃ¼l Havuzu:** $100,000
**Son Tarih:** 12 Ocak 2026
**YarÄ±ÅŸma Linki:** https://www.kaggle.com/competitions/google-tunix-hackathon

### Ã–dÃ¼l DaÄŸÄ±lÄ±mÄ±
- ğŸ¥‡ 1. Yer: $30,000
- ğŸ¥ˆ 2. Yer: $25,000
- ğŸ¥‰ 3. Yer: $15,000
- 4-6. Yer: Her biri $10,000

### Gereksinimler
1. âœ… Tunix kullanarak Ã§alÄ±ÅŸan bir eÄŸitim pipeline'Ä±
2. âœ… Gemma2 2B veya Gemma3 1B modeli
3. âœ… Kaggle Writeup (maksimum 1,500 kelime)
4. âœ… Public Kaggle Notebook
5. âœ… YouTube video (maksimum 3 dakika)

---

## ğŸ”§ Tunix KÃ¼tÃ¼phanesi

### Genel BakÄ±ÅŸ
Tunix (Tune-in-JAX), Google tarafÄ±ndan geliÅŸtirilen JAX tabanlÄ± bir LLM post-training kÃ¼tÃ¼phanesidir.

**Resmi Kaynaklar:**
- GitHub: https://github.com/google/tunix
- DokÃ¼mantasyon: https://tunix.readthedocs.io
- PyPI: `google-tunix`

### Kurulum

#### PyPI (Ã–nerilen)
```bash
pip install "google-tunix[prod]"
```

#### GitHub'dan
```bash
pip install git+https://github.com/google/tunix
```

#### Kaynak Koddan (GeliÅŸtirme)
```bash
git clone https://github.com/google/tunix.git
cd tunix
pip install -e ".[dev]"
```

#### SGLang-Jax DesteÄŸi (Opsiyonel)
```bash
git clone git@github.com:sgl-project/sglang-jax.git
cd sglang-jax/python
pip install -e .
```

### Ana Ã–zellikler

#### 1. Supervised Fine-Tuning (SFT)
- Full weights fine-tuning
- Parameter-efficient yÃ¶ntemler: LoRA ve QLoRA

#### 2. Reinforcement Learning
- **PPO (Proximal Policy Optimization)**
- **GRPO (Group Relative Policy Optimization)**
- **GSPO (Token-level Goal-Seeking Policy Optimization)**

#### 3. Knowledge Distillation
- Logit distillation
- Attention transfer
- Feature pooling stratejileri

### Teknik Ã–zellikler
- âœ… JAX-native implementation
- âœ… Flax NNX ile entegrasyon
- âœ… ModÃ¼ler ve composable componentler
- âœ… Multi-device ve multi-host desteÄŸi
- âœ… TPU optimizasyonu
- âœ… Distributed training stratejileri (DP, FSDP, TP)

### Mevcut Ã–rnek Notebook'lar
1. PEFT Gemma with QLoRA
2. GRPO training on grade school math problems
3. Logit distillation using Gemma models
4. Llama3/Qwen2 training with GRPO and SGLang-Jax

### Durum
âš ï¸ **Erken geliÅŸtirme aÅŸamasÄ±nda** - Aktif olarak yeni Ã¶zellikler ekleniyor

---

## ğŸ¤– Gemma Modelleri

### Gemma 2 2B

**Temel Ã–zellikler:**
- **Parametre SayÄ±sÄ±:** 2 milyar
- **Context UzunluÄŸu:** 8,192 token
- **Training Data:** ~2 trilyon token
- **Mimari:** Multi-query attention (MQA)
- **KullanÄ±m:** Genel amaÃ§lÄ± dil modeli

**ì¥ì :**
- Daha fazla parametre = Potansiyel olarak daha iyi performans
- YerleÅŸik multi-query attention
- GeniÅŸ training data

### Gemma 3 1B

**Temel Ã–zellikler:**
- **Parametre SayÄ±sÄ±:** 1 milyar
- **Context UzunluÄŸu:** 32,000 token (4x daha fazla!)
- **Training Data:** ~2 trilyon token
- **Mimari:** 5:1 local-to-global attention ratio
  - Local layers: 1024 token span
- **Boyut:** Gemma 2 2B'nin sadece %20'si

**ì¥ì :**
- âœ… 4x daha bÃ¼yÃ¼k context window (32K vs 8K)
- âœ… Daha kÃ¼Ã§Ã¼k deployment size
- âœ… Daha az memory requirement
- âœ… Gemma 2 2B'den daha iyi performans (kÃ¼Ã§Ã¼k olmasÄ±na raÄŸmen!)
- âœ… Optimized KV Cache
- âœ… Mobile-friendly (4GB+ RAM)
- âœ… Quantization-aware training

**KÄ±sÄ±tlamalar:**
- âš ï¸ Text-only (multimodal deÄŸil)
- âš ï¸ GÃ¶rÃ¼ntÃ¼ iÅŸleme desteÄŸi yok

### Model SeÃ§imi Ã–nerisi
**Gemma 3 1B Ã¶nerilir** Ã§Ã¼nkÃ¼:
1. Daha uzun context window (reasoning iÃ§in Ã¶nemli)
2. Daha verimli ve hÄ±zlÄ±
3. Daha az kaynak tÃ¼ketimi
4. Daha modern mimari
5. Better performance/size ratio

---

## ğŸ§  Chain-of-Thought (CoT) Reasoning

### Konsept
Chain-of-thought prompting, modellerin karmaÅŸÄ±k problemleri adÄ±m adÄ±m dÃ¼ÅŸÃ¼nme sÃ¼recini doÄŸal dil olarak ifade etmesini saÄŸlayan bir tekniktir.

### Reinforcement Learning ile Entegrasyon
- RL ile CoT birleÅŸtirilerek modeller mantÄ±ksal dÃ¼ÅŸÃ¼nme stratejilerini Ã¶ÄŸrenebilir
- OpenAI o1, DeepSeek R1 gibi modeller bu yaklaÅŸÄ±mÄ± kullanÄ±yor
- Tunix'in PPO, GRPO, GSPO algoritmalarÄ± tam da bu amaÃ§ iÃ§in tasarlanmÄ±ÅŸ

---

## ğŸ“Š Ã–nerilen Veri Setleri

### 1. GSM8K (Grade School Math 8K)
**Ã–zet:**
- 8,500 grade school math problem
- 7,500 training + 1,000 test problem
- Her problem 2-8 adÄ±m arasÄ± Ã§Ã¶zÃ¼m gerektirir
- Temel aritmetik iÅŸlemler

**Neden Ã–nemli:**
- âœ… YÃ¼ksek kaliteli, linguistically diverse
- âœ… Her problemin step-by-step Ã§Ã¶zÃ¼mÃ¼ var
- âœ… Tunix Ã¶rneklerinde kullanÄ±lÄ±yor (GRPO notebook)
- âœ… Chain-of-thought iÃ§in ideal

**BaÅŸarÄ± Metrikleri:**
- Chain-of-thought + self-consistency: %74 accuracy

### 2. MATH Dataset
**Ã–zet:**
- GSM8K'dan daha zorlu matematik problemleri
- Ãœst dÃ¼zey matematik konularÄ±
- Competition-level problems

**KullanÄ±m:**
- Daha ileri dÃ¼zey reasoning iÃ§in
- GSM8K'da iyi sonuÃ§ alÄ±ndÄ±ktan sonra

### 3. ThoughtSource
**Ã–zet:**
- Meta-dataset ve kÃ¼tÃ¼phane
- 15 farklÄ± dataset'i birleÅŸtiriyor:
  - 7 scientific/medical QA
  - 3 general-domain QA
  - 5 math word problems

**ì¥ì :**
- âœ… Ã‡eÅŸitli domain'lerden Ã¶rnekler
- âœ… CoT reasoning iÃ§in Ã¶zel olarak hazÄ±rlanmÄ±ÅŸ
- âœ… Qualitative understanding iÃ§in iyi

### 4. InfinityMATH (2025 - Yeni!)
**Ã–zet:**
- 100,000+ synthesized samples
- Program-of-Thoughts (PoT) yaklaÅŸÄ±mÄ±
- 7 high-quality dataset'ten sentezlenmiÅŸ

**ì¥ì :**
- âœ… Ã‡ok bÃ¼yÃ¼k dataset
- âœ… Modern approach (PoT)
- âœ… 2025'te yayÄ±nlandÄ± - Ã§ok gÃ¼ncel

### 5. University-level Math Reasoning Dataset
**Ã–zet:**
- 13,500+ text-only problems
- 600+ multimodal problems
- Real-world STEM problems
- Step-by-step solutions

**ì¥ì :**
- âœ… Daha zorlu problemler
- âœ… Real-world applications
- âœ… DetaylÄ± Ã§Ã¶zÃ¼mler

---

## ğŸ¯ Proje Stratejisi

### Ã–nerilen YaklaÅŸÄ±m

#### Faz 1: Temel Setup (1-2 hafta)
1. âœ… Gemma 3 1B model ile baÅŸla
2. âœ… GSM8K dataset kullan
3. âœ… Tunix GRPO trainer ile fine-tune
4. âœ… Baseline performance Ã¶lÃ§

#### Faz 2: Optimizasyon (2-3 hafta)
1. QLoRA ile parameter-efficient training
2. Hyperparameter tuning
3. Different RL algorithms dene (PPO vs GRPO vs GSPO)
4. Self-consistency implementation

#### Faz 3: Ä°leri DÃ¼zey (2-3 hafta)
1. MATH dataset ile extension
2. Multi-dataset training
3. Custom reasoning dataset oluÅŸtur
4. Ensemble methods

#### Faz 4: Finalizasyon (1 hafta)
1. Kaggle Writeup yaz
2. Video hazÄ±rla
3. Public notebook optimize et
4. Final submission

### DonanÄ±m Gereksinimleri
- **Minimum:** T4 GPU (Google Colab Ã¼cretsiz)
- **Ã–nerilen:** TPU v2/v3 (Kaggle/Colab TPU)
- **Optimal:** TPU v4 (Google Cloud)

### BaÅŸarÄ± Ä°Ã§in Kritik FaktÃ¶rler
1. âœ… Step-by-step reasoning aÃ§Ä±kÃ§a gÃ¶stermek
2. âœ… Diverse problem types
3. âœ… Self-consistency implementation
4. âœ… Efficient training pipeline
5. âœ… Ä°yi dokÃ¼mantasyon ve aÃ§Ä±klama

---

## ğŸ“š Teknik Referanslar

### Tunix
- GitHub: https://github.com/google/tunix
- Docs: https://tunix.readthedocs.io
- Blog: https://developers.googleblog.com/en/introducing-tunix-a-jax-native-library-for-llm-post-training/

### Gemma
- Official Tutorial: https://ai.google.dev/gemma/docs/recurrentgemma/recurrentgemma_jax_finetune
- Flax Models: https://huggingface.co/google/gemma-2-2b-jpn-it-flax

### Datasets
- GSM8K: https://github.com/openai/grade-school-math
- ThoughtSource: https://github.com/OpenBioLink/ThoughtSource
- LLM Datasets: https://github.com/mlabonne/llm-datasets

### Chain-of-Thought
- Google Research: https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/
- Awesome LLM Reasoning: https://github.com/atfortes/Awesome-LLM-Reasoning

---

## ğŸš€ Sonraki AdÄ±mlar

1. âœ… Proje yapÄ±sÄ± oluÅŸtur
2. âœ… Gerekli dependencies yÃ¼kle
3. âœ… GSM8K dataset indir
4. âœ… Basit bir training pipeline oluÅŸtur
5. âœ… Ä°lk baseline model eÄŸit
6. âœ… Evaluation framework kur

---

**GÃ¼ncelleme Tarihi:** 16 KasÄ±m 2025
**YarÄ±ÅŸma Son Tarih:** 12 Ocak 2026 (57 gÃ¼n kaldÄ±)
